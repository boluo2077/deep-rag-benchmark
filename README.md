<div align="center">

# ğŸ† [Deep RAG Benchmark](https://github.com/boluo2077/deep-rag-benchmark)

[![Knowledge Base](https://img.shields.io/badge/Knowledge%20Base-GitLab%20Handbook-blue.svg)](https://gitlab.com/gitlab-com/content-sites/handbook)
[![Dataset](https://img.shields.io/badge/Dataset-250%20Questions-green.svg)](datasets)
[![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)](LICENSE)

**[ English | [ä¸­æ–‡](README.zh-CN.md) ]**

</div>

---

## ğŸ’¡ Why This Dataset

<table>

<tr>
<td>

### Current Pain Points

- âŒ Lack of real benchmarks based on enterprise internal knowledge bases
- âŒ Mainstream RAG solutions perform poorly on multimodal and deep semantic questions
- âŒ Lack of universal benchmarks for other RAG solutions
<br>

</td>
</tr>

<tr>
<td>

### Project Highlights

- âœ… Based on the open-source enterprise knowledge base **[The GitLab handbook](https://gitlab.com/gitlab-com/content-sites/handbook)** version `2025/10/11 10:41`
- âœ… Question coverage: [Single-Text](datasets/single_text.jsonl), [Multimodal](datasets/multimodal.jsonl), [Negation Exclusion](datasets/negation_exclusion.jsonl), [Temporal Reference](datasets/temporal_reference.jsonl), [Contextual Anaphora](datasets/contextual_anaphora.jsonl), [Multi-hop Reasoning](datasets/multi-hop_reasoning.jsonl)
- âœ… Includes original knowledge base files, can be used to evaluate most RAG solutions; rich metadata for easy evaluation and tuning
<br>

</td>
</tr>

</table>

> Mainstream RAG solutions: Vector similarity retrieval + Keyword matching retrieval + Reranking

<br>

## âš ï¸ Important Notice

<table>

<tr>
<td>â—</td>
<td>

**Evaluation scripts need to be written by yourself**  
Currently only provides datasets, will be supplemented in future versions

</td>
</tr>

<tr>
<td>ğŸ¤–</td>
<td>

**Answers are for reference only**  
Data is AI-generated and manually filtered, but 100% accuracy cannot be guaranteed

</td>
</tr>

</table>

<br>

## ğŸ˜… Problems with Mainstream RAG Solutions

<table>
<tr>
<td width="25%">

### ğŸš« Negation Blindness
```
ğŸ‘¤ User: "What beverages contain no caffeine?"
ğŸ¤– RAG: "Starbucks latte contains 150mg caffeine..."
ğŸ‘¤ User: "Which departments haven't submitted Q3 budget?"
ğŸ¤– RAG: "Departments submitted: Marketing, R&D..."
ğŸ‘¤ User: "ğŸ˜¤ğŸ˜¤ğŸ˜¤ [table flip.gif]"
```
**Root Cause**: Ignores "not", "no", "except"

</td>
<td width="25%">

### â° Temporal Awareness Disorder
```
ğŸ‘¤ User: "Today's USD exchange rate?"
ğŸ¤– RAG: "March 2023 rate was 6.89..."
ğŸ‘¤ User: "Last quarter's revenue growth?"
ğŸ¤– RAG: "Q3 2019 revenue grew 15%..."
ğŸ‘¤ User: "ğŸ˜¤ Do you know which day is 'today'?"
```
**Root Cause**: Doesn't understand "today", "yesterday", "last quarter"

</td>
<td width="25%">

### ğŸ’¬ Context Amnesia
```
ğŸ‘¤ Round 1: "Tesla's latest earnings?"
ğŸ¤– "Q3 net profit $2.3B..."
ğŸ‘¤ Round 2: "What about their self-driving?"
ğŸ¤– "Self-driving refers to vehicles without..."
ğŸ‘¤ User: "ğŸ˜¤ğŸ˜¤ğŸ˜¤ [keyboard smash.gif]"
```
**Root Cause**: Each conversation is a "brand new start"

</td>
<td width="25%">

### ğŸ”— Multi-hop Reasoning Deficit
```
ğŸ‘¤ HR: "What was Zhang San's supervisor's performance last year?"
ğŸ§  Normal thinking: Zhang Sanâ†’Architectureâ†’Li Siâ†’Performanceâ†’A+
ğŸ¤– RAG thinking: Here's Zhang San's resume and last year's performance!
ğŸ¤– RAG: "Zhang San...performance...last year..."
ğŸ‘¤ HR: "ğŸ˜¤ğŸ˜¤ğŸ˜¤ [blood pressure spikes.gif]"
```
**Root Cause**: Single-threaded only, can't reason Aâ†’Bâ†’C

</td>
</tr>
</table>

> Deep dive into failure cases **[ğŸ‘‰ğŸ» Why-Do-Mainstream-RAG-Solutions-Suck-So-Hard.md](Why-Do-Mainstream-RAG-Solutions-Suck-So-Hard.md)**

<br>

## ğŸ“ˆ Data Distribution

| ğŸ·ï¸ Type | ğŸ“ File | ğŸ“Š Count | ğŸ’¡ Core Challenge |
|:---|:---:|:---:|:---|
| ğŸ“„ Single-Text | [single_text.jsonl](datasets/single_text.jsonl) | **100** | Basic semantic retrieval capability test |
| ğŸ–¼ï¸ Multimodal | [multimodal.jsonl](datasets/multimodal.jsonl) | **50** | Image-text hybrid retrieval capability test |
| ğŸš« Negation Exclusion | [negation_exclusion.jsonl](datasets/negation_exclusion.jsonl) | **25** | Negation word recognition (not, no) |
| â° Temporal Reference | [temporal_reference.jsonl](datasets/temporal_reference.jsonl) | **25** | Temporal reasoning (today, last quarter) |
| ğŸ’¬ Contextual Anaphora | [contextual_anaphora.jsonl](datasets/contextual_anaphora.jsonl) | **25** | Multi-turn dialogue reference (it, this) |
| ğŸ”— Multi-hop Reasoning | [multi-hop_reasoning.jsonl](datasets/multi-hop_reasoning.jsonl) | **25** | Chain reasoning retrieval (A â†’ B â†’ C) |

<br>

## ğŸ—‚ï¸ Data Format

```
{
  "id": 0,                          // ğŸ†” Unique identifier
  "type": "Type",                   // ğŸ·ï¸ Question type
  "context": "Previous question",   // ğŸ’¬ Dialogue context (only for contextual_anaphora.jsonl)
  "question": "Question",           // â“ Test question
  "think": "Retrieval strategy",    // ğŸ§  Reasoning process (to understand correct retrieval path)
  "retrieval": [                    // ğŸ” Step-by-step retrieval path
    {
      "File path 0": ["Substring 0", "Substring 1"],
      "File path 1": ["Substring 2", "Substring 3"]
    },
    {
      "File path n": ["Substring n-1", "Substring n"]
    }
  ],
  "answer": "Answer"                // âœ… Standard answer (for exact match verification)
}
```

<br>

## ğŸ“ Project Structure

```
ğŸ“ deep-rag-benchmark/
â”‚
â”œâ”€â”€ ğŸ“‚ datasets/                         # Dataset folder
â”‚   â”œâ”€â”€ single_text.jsonl               # ğŸ“„ Single-Text (100 items)
â”‚   â”œâ”€â”€ multimodal.jsonl                # ğŸ–¼ï¸ Multimodal (50 items)
â”‚   â”œâ”€â”€ negation_exclusion.jsonl        # ğŸš« Negation Exclusion (25 items)
â”‚   â”œâ”€â”€ temporal_reference.jsonl        # â° Temporal Reference (25 items)
â”‚   â”œâ”€â”€ contextual_anaphora.jsonl       # ğŸ’¬ Contextual Anaphora (25 items)
â”‚   â””â”€â”€ multi-hop_reasoning.jsonl       # ğŸ”— Multi-hop Reasoning (25 items)
â”‚
â”œâ”€â”€ ğŸ“‚ content/handbook/                 # ğŸ¢ GitLab Handbook knowledge base
â”‚   â”œâ”€â”€ about/                          # About handbook
â”‚   â”œâ”€â”€ communication/                  # Communication guidelines
â”‚   â”œâ”€â”€ company/                        # Company information
â”‚   â”œâ”€â”€ engineering/                    # Engineering dept
â”‚   â”œâ”€â”€ finance/                        # Finance dept
â”‚   â”œâ”€â”€ marketing/                      # Marketing dept
â”‚   â”œâ”€â”€ sales/                          # Sales dept
â”‚   â””â”€â”€ ...                             # More department docs
â”‚
â”œâ”€â”€ ğŸ“‚ images/                           # ğŸ–¼ï¸ Multimodal data images
â”‚   â”œâ”€â”€ finance/expenses/               # Finance-related images
â”‚   â”œâ”€â”€ marketing/                      # Marketing-related images
â”‚   â”œâ”€â”€ tools-and-tips/                 # Tool usage images
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         # English documentation
â”œâ”€â”€ ğŸ“„ README.zh-CN.md                   # Chinese documentation
â”œâ”€â”€ ğŸ“„ Why-Do-Mainstream-RAG-Solutions-Suck-So-Hard.md
â”œâ”€â”€ ğŸ“„ Why-Do-Mainstream-RAG-Solutions-Suck-So-Hard.zh-CN.md
â””â”€â”€ ğŸ“„ LICENSE                           # Apache-2.0 open source license
```

<br>

## ğŸ¯ Question Types

---

### ğŸ“„ Single-Text (100 items)

<details>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Tests **basic retrieval capabilities** of RAG systems
- Answers come from continuous text within a single document

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Single-Text",
  "question": "What is the name of the group that consists of VPs who report directly to a member of E-Group?",
  "think": "I need to find the definition of different leadership groups within GitLab's structure. I will search the 'company/structure.md' document for terms like 'VP', 'E-Group', and 'reports directly'. The section on 'VP-Directs' provides a clear definition that matches the question.",
  "retrieval": [
    {
      "company/structure.md": [
        "VP-Directs are a subset of GitLab VPs who report directly to a member of E-Group. They are members of the VP-Directs Group."
      ]
    }
  ],
  "answer": "VP-Directs Group"
}
```

</details>

<br>

### ğŸ–¼ï¸ Multimodal (50 items)

<details>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Tests multimodal information integration capability of RAG systems
- Answers **must come from images**, not present in knowledge base text

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Multimodal",
  "question": "What is the final item listed on the approved office supplies list?",
  "think": "The user is asking for the last item on the 'Approved Office Supplies List'. I will search the provided documents for this list. The document 'finance/expenses.md' contains a section on 'Office Supplies & consumables' and an image with the markdown `![Approved Office Supplies List](/images/finance/expenses/approved-office-supplies-list.png)`. The text in the document does not contain the full list, so I must retrieve the image to find the last item.",
  "retrieval": [
    {
      "finance/expenses.md": [
        "![Approved Office Supplies List](/images/finance/expenses/approved-office-supplies-list.png)"
      ]
    }
  ],
  "answer": "Document shredding fees"
}
```

</details>

<br>

### ğŸš« Negation Exclusion (25 items)

<details open>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Questions contain **"not", "no", "except"** and other negation words
- Contains highly similar **distractor keywords**, easy to mis-retrieve

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Negation Exclusion",
  "question": "Within GitLab's organizational structure, which marketing-related phase focused on turning a prospect into a happy user is not a formal 'Division' or 'Department' like Sales or Engineering?",
  "think": "The question is heavily loaded with terms related to formal company structure, such as 'organizational structure', 'Division', and 'Department'. These keywords are designed to mislead the RAG system into searching `company/structure.md`. However, the question is asking for a phase in the marketing journey, which is detailed in `marketing/_index.md`. The correct answer is one of the stages of the customer journey.",
  "retrieval": [ // retrieval[0] is incorrect retrieval! retrieval[1:] is correct retrieval
    {
      "company/structure.md": [
        "Divisions: the area under one executive. e.g. the Engineering division. Departments: lead by Directors or VPs and comprise multiple teams or sub-departments e.g. the Infrastructure department within the Engineering division"
      ]
    },
    {
      "marketing/_index.md": [
        "The journey's purpose is to provide a clear and cohesive experience to a prospect/customer from the minute they become Aware of GitLab, to Considering the platform and Converting into a happy customer, and then of course Expanding over time and becoming an Evangelist."
      ]
    }
  ],
  "answer": "Converting"
}
```

</details>

<br>

### â° Temporal Reference (25 items)

<details>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Questions contain **"today", "this quarter", "last month"** and other relative time expressions
- Need to parse temporal reference first, then retrieve corresponding data

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Temporal Reference",
  "question": "When did the current fiscal quarter begin?",
  "think": "The current date is November 11, 2025. First, I need to determine the current fiscal quarter by checking the definitions in the knowledge base. The file 'finance/_index.md' states that 'Q4: November 1 through January 31'. Since November 11 falls within this range, the current quarter is Q4. The start date for Q4 is November 1. The current calendar year is 2025, so the full date is 2025-11-01.",
  "retrieval": [  // Reference time: November 11, 2025, Tuesday 11:11:11
    {
      "finance/_index.md": [
        "Q4: November 1 through January 31"
      ]
    }
  ],
  "answer": "2025-11-01"
}
```

</details>

<br>

### ğŸ’¬ Contextual Anaphora (25 items)

<details>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Questions contain **"it", "they", "this", "that"** and other anaphoric expressions
- Need to combine with `context` (previous conversation round) to understand referent
- Questions are extremely brief and vague, retrieval without context will fail

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Contextual Anaphora",
  "context": "What is the prefix for Group Channels in Slack?",
  "question": "And for the next one?",
  "think": "The user is asking about the prefix for the next channel category listed after 'Group Channels'. Without context, 'the next one' is ambiguous. A naive search might look for general categories, possibly landing in the marketing handbook which discusses departments, leading to an incorrect file. The correct approach is to locate 'Group Channels (g_)' in 'communication/chat.md', identify the following category, 'Location Channels (loc_)', and then find its prefix.",
  "retrieval": [ // retrieval[0] is incorrect retrieval! retrieval[1:] is correct retrieval
    {
      "marketing/_index.md": [
        "The GitLab Marketing team operates as one team and is organized by the following departments: Integrated Marketing, Brand and Product Marketing"
      ]
    },
    {
      "communication/chat.md": [
        "Location Channels (loc_) | These channels are used to help GitLab team-members who are in the same general region of the world to talk about get-togethers and other location-specific items."
      ]
    }
  ],
  "answer": "loc_"
}
```

</details>

<br>

### ğŸ”— Multi-hop Reasoning (25 items)

<details>
<summary><b>Click to expand</b></summary>

#### ğŸ“‹ Characteristics
- Answers require **2+ steps of cross-document retrieval**
- `retrieval` contains multiple file paths
- Questions don't contain keywords from the final answer document

#### ğŸ’¡ Example

```json
{
  "id": 0,
  "type": "Multi-hop Reasoning",
  "question": "Through a multi-hop reasoning process, what is the designated output for the department managed by the executive who uses the '#ciso' communication channel?",
  "think": "First, I need to find the executive role associated with the '#ciso' channel in 'communication/chat.md'. The table 'Getting in touch with the e-group' shows this is the CISO. Second, I need to find the output of the CISO's division in the 'Organized by Output' table within 'company/structure.md'. This table lists the Security division's output.",
  "retrieval": [
    {
      "communication/chat.md": [
        "| CISO | #ciso |"
      ]
    },
    {
      "company/structure.md": [
        "| Security | Enable trust |"
      ]
    }
  ],
  "answer": "Enable trust"
}
```

</details>

---

<div align="center">

**If this project helps you, please click the â­ Star in the upper right corner!**

*Your Star is our motivation for continuous improvement ğŸ’ª*

![Star History Chart](https://api.star-history.com/svg?repos=boluo2077/deep-rag-benchmark&type=Date)

---

<a href="#-deep-rag-benchmark">
  <img src="https://img.shields.io/badge/â¬†ï¸-Back%20to%20Top-blue?style=for-the-badge" alt="Back to Top">
</a>

</div>